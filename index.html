<!doctype html>
<html lang="en">
<head>
	<!-- Required meta tags -->
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

	<!-- Bootstrap CSS -->
	<link href="resources/bootstrap.min.css" rel="stylesheet">
	<title>Unsupervised Volumetric Animation</title>
</head>
<body>

	<section class="jumbotron text-center">
		<div class="container">
			<h1 class="jumbotron-heading">Unsupervised Volumetric Animation</h1>
			<h2 class="jumbotron-heading">Supplementary Material</h1>

	</div>
	</section>
        <div class="container pt-5">
                        <p class="lead"> If videos aren't loading, please unzip the archive to your local drive.</p>
	
			<h2>Animation results on VoxCeleb</h2>
			<p class="lead"> In the first row we show driving, in the first column is source. Second and Forth rows demonstrate the obtrained animations and same animations under novel view, were we rotate the object along y-axis by -15째 and 15째 degrees. We also show predicted normals, depth and LBS weighs. </p>

                        <div class="row">
                                <div class="col-md-6">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/animations/vox-example-1.mp4" type="video/mp4" />
					</video>
				</div>
                                <div class="col-md-6">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/animations/vox-example-2.mp4" type="video/mp4" />
					</video>
				</div>
			</div>
			<br/>
			<h2>Animation results on TEDXPeople</h2>
			<p class="lead"> In the first row we show driving, in the first column is source. Second and Forth rows demonstrate the obtrained animations and same animations under novel view, were we rotate the object along y-axis by -15째 and 15째 degrees. We also show predicted normals, depth and LBS weighs. </p>

                        <div class="row">
                                <div class="col-md-6">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/animations/tedx-example-3.mp4" type="video/mp4" />
					</video>
				</div>
                                <div class="col-md-6">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/animations/tedx-example-4.mp4" type="video/mp4" />
					</video>
				</div>
			</div>

			<br/>
			<h2>Comparison with MRAA and LIA on VoxCeleb</h2>
			<p class="lead"> In the first row we show driving, in the first column is source. Second and Forth columns are our method, while third and fifth is MRAA. Note that our method preserve the shape of the face very well, while MRAA and LIA significalty distort the shape. </p>

                        <div class="row">
                                <div class="col-md-6">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/comparisons/vox-example-1.mp4" type="video/mp4" />
					</video>
				</div>
                                <div class="col-md-6">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/comparisons/vox-example-2.mp4" type="video/mp4" />
					</video>
				</div>
			</div>


			<br/>
			<h2>Comparison with MRAA on TEDXPeople</h2>
			<p class="lead"> In the first row we show driving, in the first column is source. Second and Forth columns are our method, while third and fifth is MRAA. Note that even in very chalanging case our method could succsessfully detect movement of the hands while mraa fails to do it. </p>

                        <div class="row">
                                <div class="col-md-6">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/comparisons/tedx-example-2.mp4" type="video/mp4" />
					</video>
				</div>
                                <div class="col-md-6">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/comparisons/tedx-example-1.mp4" type="video/mp4" />
					</video>
				</div>
			</div>

  			<br/>

			<h2>Novel-view synthesis on VoxCeleb</h2>
			<p class="lead"> Here we show results rendered under a different viewpoints. We also show the correspondig depth, normals and LBS weights. </p>

                        <div class="row">
                                <div class="col-md-8" style="display: block; margin-left: auto; margin-right: auto;">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/novel-view-synthesis/vox-example.mp4" type="video/mp4" />
					</video>
				</div>
			</div>


			<br/>
			<h2>Novel-view synthesis on TEDXPeople</h2>
			<p class="lead"> Here we show results rendered under a different viewpoints. We also show the correspondig depth, normals and LBS weights. </p>

                        <div class="row">
                                <div class="col-md-8" style="display: block; margin-left: auto; margin-right: auto;">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/novel-view-synthesis/tedx-example.mp4" type="video/mp4" />
					</video>
				</div>
			</div>

 			<br/>
			<h2>Novel-view synthesis on cats</h2>
			<p class="lead"> Here the model is trained on only images, however 3D bias provided by PnP helps to discover meanigfull geometry also in this challenging case. </p>

                        <div class="row">
                                <div class="col-md-6" style="display: block; margin-left: auto; margin-right: auto;">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/cats/example-1.mp4" type="video/mp4" />
					</video>
				</div>
                                <div class="col-md-6" style="display: block; margin-left: auto; margin-right: auto;">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/cats/example-2.mp4" type="video/mp4" />
					</video>
				</div>
	
			</div>


  			<br/>

			<h2>Comparison of direct prediction and PnP based.</h2>
			<p class="lead"> Here we show only models trained with a single part, i.e. only <i>G-phase</i>. You can see that  <i>Direct</i> aproach learned flat geometry, while PnP-based produce proper geometry. </p>

                        <div class="row">
                                <div class="col-md-6" style="display: block; margin-left: auto; margin-right: auto;">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/pnp-vs-direct/example-1.mp4" type="video/mp4" />
					</video>
				</div>
                                <div class="col-md-6" style="display: block; margin-left: auto; margin-right: auto;">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/pnp-vs-direct/example-2.mp4" type="video/mp4" />
					</video>
				</div>
	                        <div class="col-md-6" style="display: block; margin-left: auto; margin-right: auto;">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/pnp-vs-direct/example-3.mp4" type="video/mp4" />
					</video>
				</div>
	                        <div class="col-md-6" style="display: block; margin-left: auto; margin-right: auto;">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/pnp-vs-direct/example-4.mp4" type="video/mp4" />
					</video>
				</div>
	
			</div>


  			<br/>



			<h2>Random generation on VoxCeleb</h2>
			<p class="lead"> Note that since our model learns lattent space, it allow to generate random identities. Here we sample random identity from the lattent space (i.e. use standart normal noise as embedding), and animate it using the driving from the test set. While the texture may lag behing GAN-based methods, which is a known problem of auto-decoder methods, the geometry is very reasonable. </p>

                        <div class="row">
                                <div class="col-md-8" style="display: block; margin-left: auto; margin-right: auto;">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/random/vox-example.mp4" type="video/mp4" />
					</video>
				</div>

			</div>

   			<br/>
			<h2>Random generation on TEDXPeople</h2>
			<div class="row">
				<div class="col-md-8" style="display: block; margin-left: auto; margin-right: auto;">
					<video class="video-fluid w-100" controls autoplay loop muted>
						<source src="video_sequences/random/tedx-example.mp4" type="video/mp4" />
					</video>
				</div>

			</div>

    
                 
	</div>
</body>
</html>
